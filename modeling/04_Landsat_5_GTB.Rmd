---
title: "eePlumB Develop and Apply GTB for Landsat 5"
author: "ROSSyndicate"
date: "2024-01-25"
output: html_document
editor_options:
  markdown:
    wrap: 80
---

```{r setup, echo = F}
libs = c('reticulate', 'tidyverse')

package_loader <- function(x) {
    if (x %in% installed.packages()) {
      library(x, character.only = TRUE)
    } else {
      install.packages(x)
      library(x, character.only = TRUE)
    }
}

lapply(libs, package_loader)
```

# Purpose

This script develops and applies Gradient Tree Boost Models to the Landsat 5 image
stack.

## Activate conda environment

Check for virtual environment and activate, otherwise, set up virtual
environment.

```{r, conda env}
if (!dir.exists("env")) {
  source("pySetup.R")
} else {
  use_condaenv(file.path(getwd(), "env"))
}
```

### Settings/modules

Import the needed modules and set model version date

```{python}
import ee
import os
import time
import pandas as pd
import geopandas as gpd

v_date = '2024-01-08'
```

## GEE Setup

```{python}
ee.Authenticate()
```

When your browser states 'You are now authenticated with the gcloud CLI', the
authentication is complete. This authentication is valid for 7 days.

Now, we need to initialize our GEE session. You may need to change the project 
name to one you own if you do not have write access.

```{python}
ee.Initialize(project = 'ee-ross-superior')
```

# Import assets

These assets were created in the 03_Train_Test_Split.Rmd file

```{python}
training_ls5 = ee.FeatureCollection("projects/ee-ross-superior/assets/train-test/training_ls5")
testing_ls5 = ee.FeatureCollection("projects/ee-ross-superior/assets/train-test/testing_ls5")
```

## Train the GTB model

```{python}
ls_input_feat = ["Red", "Green", "Blue", "B5", "B6", "B7"]
output_label = "class"
class_values = (['cloud',
  'openWater',
  'lightNearShoreSediment',
  'offShoreSediment',
  'darkNearShoreSediment'])
```

### Landsat 5

```{python}
trainedGTB_ls5 = (ee.Classifier.smileGradientTreeBoost(10).train(
  features = training_ls5,
  classProperty = 'byte_property',
  inputProperties = ls_input_feat
))

print(trainedGTB_ls5.getInfo())
```

Unfortunately, there is no current mechanism to save the GTB object. This is a
bummer because you can't really set a seed for these either, however! GEE is a bit
more rudimentary and recognizes the inputs and therefore creates the same output
objects. I did a quick check of this by running the model here and then again 
in the browser. Both have identical versions, so I feel confident that GEE is
making the 'same' model. 

## Evaluate the models

### Landsat 5

```{python}
trainingMatrixGTB_ls5 = (trainedGTB_ls5
  .confusionMatrix())

#convert to pandas dataframe with class info
training_conf_l5 = (pd.DataFrame(
  trainingMatrixGTB_ls5.getInfo(),
  index=[class_values],
  columns =[class_values]
  ))
print('GTB Training Confusion Matrix for Landsat 5:')
print(training_conf_l5)

#reformat and save
training_conf_l5['mission'] = 'Landsat 5'
training_conf_l5.reset_index(inplace = True)
training_conf_l5 = training_conf_l5.rename(columns = {'level_0': 'class'})  
training_conf_l5.to_csv('data/output/GTB_'+v_date+'_l5_training_confusion.csv', index = False)

confusionMatrixGTB_ls5 = (testing_ls5
  .classify(trainedGTB_ls5)
  .errorMatrix('byte_property', "classification"))

#convert to pandas dataframe with class info
confusion_l5 = (pd.DataFrame(
  confusionMatrixGTB_ls5.getInfo(),
  index=[class_values],
  columns =[class_values]
  ))
print('GTB Confusion Matrix for Landsat 5:')
print(confusion_l5)

#reformat and save
confusion_l5['mission'] = 'Landsat 5'
confusion_l5.reset_index(inplace = True)
confusion_l5 = confusion_l5.rename(columns = {'level_0': 'class'})  
confusion_l5.to_csv('data/output/GTB_'+v_date+'_l5_confusion.csv', index = False)

acc_values_GTB_ls5 = (confusionMatrixGTB_ls5.accuracy().getInfo())
print("GTB Confusion Overall Accuracy for Landsat 5: ", acc_values_GTB_ls5)
k_GTB_ls5 = (confusionMatrixGTB_ls5.kappa().getInfo())
print("GTB kappa for LS5: ", k_GTB_ls5)
fs_GTB_ls5 = (confusionMatrixGTB_ls5.fscore().getInfo())
print('GTB fScore for each class: ', fs_GTB_ls5)
```


### Collate model stats, save to data folder

First, we'll copy over some values and make a big pandas dataframe. Note that
the df.copy() function unlinks the original list from the new one. Silly python.

```{python}
accuracy_heads = class_values.copy()
accuracy_heads.extend(['GTB_accuracy', 'GTB_kappa'])
landsat5_perf = fs_GTB_ls5.copy()
landsat5_perf.extend([acc_values_GTB_ls5, k_GTB_ls5])

performance_collation = pd.DataFrame(
  [landsat5_perf],
  index = [
    'Landsat 5'
    ],
  columns = [accuracy_heads]
  )

# reset the index
performance_collation.reset_index(inplace = True)
performance_collation.rename(columns = {'index':'satellite'}).to_csv('data/output/GTB_LS5_'+v_date+'_performance_stats.csv', index = False)
```

## Apply model to image stack for Landsat

### Load the image collection

```{python}
# list bandnames; in part for L7 bands to match l8/9
bn457 = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7', 'QA_RADSAT']
bn89 = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'QA_RADSAT']
bn = ['Blue', 'Green', 'Red', 'B5', 'B6', 'B7', 'QA_RADSAT']

# filter stack for desired PRs
ROWS = ee.List([27, 28])

def applyScaleFactors(image):
  opticalBands = image.select(bn).multiply(0.0000275).add(-0.2) #note - this applies the offset to QA RADSAT - the 0 value will now be -0.2!
  return image.addBands(opticalBands, None, True)


l5 = (ee.ImageCollection('LANDSAT/LT05/C02/T1_L2')
  .filter(ee.Filter.eq('WRS_PATH', 26))
  .filter(ee.Filter.inList('WRS_ROW', ROWS))
  .filter(ee.Filter.gte('IMAGE_QUALITY', 7))
  .select(bn457, bn)
  .map(applyScaleFactors))
```

Add QA_RADSAT mask to mask where any band was saturated

```{python}
def apply_radsat_mask(image):
  radsat = image.select('QA_RADSAT').eq(-0.2) # this is due to the application of the scaling factor
  return image.updateMask(radsat)

l5 = l5.map(apply_radsat_mask)
```

### Load modeling AOIs and clip stack

Note, some AOIs are too big to load in here and use as 'virtual' ee Feature
Collections. Given that, we have manually uploaded the shapefiles as an Earth
Engine Feature Collection.

```{python}
aoi_ee = ee.FeatureCollection('projects/ee-ross-superior/assets/aoi/Superior_AOI_modeling')

#Calculate total area of AOI
def calc_area(feat):
  feat_area = feat.geometry().area()
  feat_area_ha = ee.Number(feat_area).divide(1e5)
  return feat.set('area_ha', feat_area_ha)

aoi_area = aoi_ee.map(calc_area).aggregate_sum('area_ha')
aoi_area_ha = aoi_area.getInfo()
print('total AOI area: ', aoi_area_ha)
```

And then clip each image by that aoi

```{python}
# clip images to aoi
def clip(image):
  return image.clip(aoi_ee.geometry())

l5_aoi = l5.map(clip)
```

Load other AOIs to summarize over

```{python}
# aoi_no_sc_gpd = gpd.read_file('data/aoi/Superior_AOI_minus_shoreline_contamination.shp')
# aoi_no_sc_ee = gm.geopandas_to_ee(aoi_no_sc_gpd)
aoi_no_sc_ee = ee.FeatureCollection('projects/ee-ross-superior/assets/aoi/Superior_AOI_minus_shoreline_contamination')

aoi_no_sc_area = aoi_no_sc_ee.map(calc_area).aggregate_sum('area_ha')
aoi_no_sc_area_ha = aoi_no_sc_area.getInfo()
print('total AOI area without shoreline contamination: ', aoi_no_sc_area_ha)

# aoi_sc_gpd = gpd.read_file('data/aoi/Superior_shoreline_contamination.shp')
# aoi_sc_ee = gm.geopandas_to_ee(aoi_sc_gpd)
aoi_sc_ee = ee.FeatureCollection('projects/ee-ross-superior/assets/aoi/Superior_shoreline_contamination')

aoi_sc_area = aoi_sc_ee.map(calc_area).aggregate_sum('area_ha')
aoi_sc_area_ha = aoi_sc_area.getInfo()
print('total AOI area identified as shoreline contamination: ', aoi_sc_area_ha)
```

#### Helper functions

```{python}
# get CRS info
img_crs = l5.first().projection()
img_crsTrans = img_crs.getInfo().get('transform')

#function to apply the GTB model
def applyGTB_ls5(image):
  # Select the bands that correspond to the input features of the GTB model
  imageFeatures = image.select(ls_input_feat)
  missDate = image.get('missDate')
  # Classify the image using the trained GTB model
  classifiedImage = (imageFeatures
    .classify(trainedGTB_ls5)
    .set('missDate', missDate))
  return image.addBands(classifiedImage)


# save each value as its own band and mask
def extract_classes(image):
  cl = image.select('classification')
  cloud = cl.eq(0).rename('cloud').selfMask()
  openWater = cl.eq(1).rename('openWater').selfMask()
  lightNSSed = cl.eq(2).rename('lightNSSed').selfMask()
  OSSed = cl.eq(3).rename('OSSed').selfMask()
  dNSSed = cl.eq(4).rename('dNSSed').selfMask()
  classified = cl.gte(0).rename('classified').selfMask()
  img_addBand = (image.addBands(cloud)
    .addBands(openWater)
    .addBands(lightNSSed)
    .addBands(OSSed)
    .addBands(dNSSed)
    .addBands(classified))
  return img_addBand


def applyPerMissionDate_ls5(missDate):
  mission = ee.String(missDate).slice(0,9)
  date = ee.String(missDate).slice(10,20)
  short_stack = (l5_aoi
    .filter(ee.Filter.eq('SPACECRAFT_ID', mission))
    .filter(ee.Filter.eq('DATE_ACQUIRED', date)))
  oneMissDate = short_stack.mean()
  ls_miss_date_GTB = applyGTB_ls5(oneMissDate)
  ls_GTB_class = extract_classes(ls_miss_date_GTB)
  return (ls_GTB_class.set('missDate', missDate))

```

### consolidate stack by image date

```{python}
def addImageDate(image):
  mission = image.get('SPACECRAFT_ID')
  date = image.date().format('YYYY-MM-dd')
  missDate = ee.String(mission).cat('_').cat(ee.String(date))
  return image.set('missDate', missDate)

l5_aoi = l5_aoi.map(addImageDate)

# summarize by missionDate field
uniqueMissDate_l5 = l5_aoi.aggregate_array('missDate').distinct()

```

### Create mosaics

```{python}
def mosaicStack_l5(missDate):
  md_GTB = applyPerMissionDate_ls5(missDate)
  return md_GTB

newStack_list_l5 = uniqueMissDate_l5.map(mosaicStack_l5)
newStack_l5 = ee.ImageCollection(newStack_list_l5)

```

### Lighten up each of the stacks to only the bands we care about

```{python}
lightStack_l5 = newStack_l5.select([
    'classified',
    'cloud',
    'openWater',
    'lightNSSed',
    'OSSed',
    'dNSSed'
    ])

```

### Calculate area per image and export

```{python}
#because these geometries are rather large, we have to create a function for each AOI
def calcArea_aoi(image):
  areaImage =  (image
    .multiply(ee.Image.pixelArea()).divide(1e5))

  area = areaImage.reduceRegions(
    collection = aoi_ee,
    reducer = ee.Reducer.sum().forEachBand(areaImage),
    crs = img_crs,
    crsTransform = img_crsTrans
  )

  missDate = image.get('missDate')

  # Create a feature with the calculated area and properties
  a = area.first().set({'missDate': missDate, 
                        'area_ha': aoi_area_ha, 
                        'extent': 'aoi'})
  
  return ee.FeatureCollection(a)


def calcArea_nosc(image):
  areaImage =  (image
    .multiply(ee.Image.pixelArea()).divide(1e5)
    .clip(aoi_no_sc_ee.geometry()))
  
  area = areaImage.reduceRegions(
    collection = aoi_no_sc_ee,
    reducer = ee.Reducer.sum().forEachBand(areaImage),
    crs = img_crs,
    crsTransform = img_crsTrans
  )
  
  missDate = image.get('missDate')
  
  # Create a feature with the calculated area and properties
  a = area.first().set({'missDate': missDate, 
                        'area_ha': aoi_no_sc_area_ha, 
                        'extent': 'aoi no sc'})
  
  return ee.FeatureCollection(a)


def calcArea_sc(image):
  areaImage =  (image
    .multiply(ee.Image.pixelArea()).divide(1e5)
    .clip(aoi_sc_ee.geometry()))

  area = areaImage.reduceRegions(
    collection = aoi_sc_ee,
    reducer = ee.Reducer.sum().forEachBand(areaImage),
    crs = img_crs,
    crsTransform = img_crsTrans
  )

  missDate = image.get('missDate')

  # Create a feature with the calculated area and properties
  a = area.first().set({'missDate': missDate, 
                        'area_ha': aoi_sc_area_ha, 
                        'extent': 'shoreline contamination'})
  
  return ee.FeatureCollection(a)

```

And then map them over all the stacks

```{python}

allAreas_l5_aoi = lightStack_l5.map(calcArea_aoi)

allAreas_l5_nosc = lightStack_l5.map(calcArea_nosc)

allAreas_l5_sc = lightStack_l5.map(calcArea_sc)

```


#### Landsat 5

```{python}
## export to drive
export_summary_5_aoi = (ee.batch.Export.table.toDrive(
  collection = allAreas_l5_aoi,
  selectors = ['missDate', 'classified', 'cloud', 'openWater', 'lightNSSed','OSSed', 'dNSSed', 'area_ha', 'extent'],
  description = 'gradientTreeBoost_landsat_5_stack_v' + v_date,
  folder = 'eePlumB_classification_v2024-01-08',
  fileFormat = 'csv'))

export_summary_5_aoi.start()

export_summary_5_nosc = (ee.batch.Export.table.toDrive(
  collection = allAreas_l5_nosc,
  selectors = ['missDate', 'classified', 'cloud', 'openWater', 'lightNSSed','OSSed', 'dNSSed', 'area_ha', 'extent'],
  description = 'gradientTreeBoost_landsat_5_stack_nosc_v' + v_date,
  folder = 'eePlumB_classification_v2024-01-08',
  fileFormat = 'csv'))

export_summary_5_nosc.start()


export_summary_5_sc = (ee.batch.Export.table.toDrive(
  collection = allAreas_l5_sc,
  selectors = ['missDate', 'classified', 'cloud', 'openWater', 'lightNSSed','OSSed', 'dNSSed', 'area_ha', 'extent'],
  description = 'gradientTreeBoost_landsat_5_stack_sc_v' + v_date,
  folder = 'eePlumB_classification_v2024-01-08',
  fileFormat = 'csv'))

export_summary_5_sc.start()
```

## Export GeoTiffs to drive

Load task checker!

```{python}
##Function for limiting the max number of tasks sent to
#earth engine at one time to avoid time out errors
def maximum_no_of_tasks(MaxNActive, waitingPeriod):
  ##maintain a maximum number of active tasks
  ## initialize submitting jobs
  ts = list(ee.batch.Task.list())
  NActive = 0
  for task in ts:
     if ('RUNNING' in str(task) or 'READY' in str(task)):
         NActive += 1
  ## wait if the number of current active tasks reach the maximum number
  ## defined in MaxNActive
  while (NActive >= MaxNActive):
    time.sleep(waitingPeriod) # if reach or over maximum no. of active tasks, wait for 2min and check again
    ts = list(ee.batch.Task.list())
    NActive = 0
    for task in ts:
      if ('RUNNING' in str(task) or 'READY' in str(task)):
        NActive += 1
  return()

```

### Raster Export

First, we need to define a function to use the data from the multiple classified
bands to populate a single band.

```{python}
fromlist = [0,1,2,3,4]
tolist = [1,2,3,4,5]
def classifications_to_one_band(image):
  cl = image.select('classification').clip(aoi_ee.geometry())
  img_classified = (cl
    .remap(fromlist, tolist, defaultValue = -99)
    .rename('reclass'))
  return image.addBands(img_classified)

```


### GTB images for Landsat 5

```{python}
date_length_5 = len(uniqueMissDate_l5.getInfo())

for d in range(date_length_5):
  md = uniqueMissDate_l5.get(d)
  print(md.getInfo())
  print(str(d+1) + ' of ' + str(date_length_7))
  image = (newStack_l5
    .filter(ee.Filter.eq('missDate', md))
    .first()
    .clip(aoi_ee.geometry()))
  image_new_class = (classifications_to_one_band(image)
    .select('reclass'))
  export_image = ee.batch.Export.image.toDrive(
    image = image_new_class,
    region = aoi_ee.geometry(),
    description = 'GTB_v' + v_date + '_' + str(md.getInfo()),
    folder = 'GTB_LS5_v'+v_date,
    scale = 30,
    crs = img_crs,
    maxPixels = 1e13)
  
  #Check how many existing tasks are running and take a break of 5 mins if it's >10
  maximum_no_of_tasks(10, 5*60)
  #Send next task.
  export_image.start()

for d in range(date_length_5):
  md = uniqueMissDate_l5.get(d)
  print(md.getInfo())
  print(str(d+1) + ' of ' + str(date_length_5))
  image = (newStack_l5
    .filter(ee.Filter.eq('missDate', md))
    .first()
    .clip(aoi_ee.geometry()))
  image_new_class = (classifications_to_one_band(image)
    .select('reclass'))
  export_image = ee.batch.Export.image.toAsset(
    image = image_new_class,
    region = aoi_ee.geometry(),
    description = 'GTB_v' + v_date + '_' + str(md.getInfo()),
    assetId = 'projects/ee-ross-superior/assets/LS5/'+'GTB_LS5)'+str(md.getInfo())+'_v'+v_date,
    scale = 30,
    crs = img_crs,
    maxPixels = 1e13)
  
  #Check how many existing tasks are running and take a break of 5 mins if it's >10
  maximum_no_of_tasks(10, 5*60)
  #Send next task.
  export_image.start()

```


