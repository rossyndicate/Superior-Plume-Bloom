---
title: "eePlumB Develop and Apply GTB for Landsat 7"
author: "ROSSyndicate"
date: "2024-04-26"
output: html_document
editor_options:
  markdown:
    wrap: 80
---

```{r setup, echo = F}
libs = c('reticulate', 'tidyverse')

package_loader <- function(x) {
    if (x %in% installed.packages()) {
      library(x, character.only = TRUE)
    } else {
      install.packages(x)
      library(x, character.only = TRUE)
    }
}

lapply(libs, package_loader)
```

# Purpose

This script develops and applies Gradient Tree Boost Models to the Landsat 7
image stack.

## Activate conda environment

Check for virtual environment and activate, otherwise, set up virtual
environment.

```{r, conda env}
if (!dir.exists("env")) {
  source("pySetup.R")
} else {
  use_condaenv(file.path(getwd(), "env"))
}
```

### Settings/modules

Import the needed modules and set model version date

```{python}
import ee
import os
import time
import matplotlib.pyplot as plt
import pandas as pd

v_date = '2024-04-26'
```

## GEE Setup

```{python}
ee.Authenticate()
```

When your browser states 'Google Earth Engine authentication successful!' or the
console reads "TRUE", the
authentication is complete. 

Now, we need to initialize our GEE session. You may need to change the project 
name to one you own if you do not have write access.

```{python}
ee.Initialize(project = 'ee-ross-superior')
```


Import custom functions (these require ee.Authenticate())
```{python}
import imp
imp.load_source("gee_funx", "modeling/gee_functions.py")
import gee_funx as gf
```

# Import assets

These assets were created in the 03_Train_Test_Split.Rmd file

```{python}
training_ls7 = ee.FeatureCollection("projects/ee-ross-superior/assets/train-test/training_ls7_v2024")
testing_ls7 = ee.FeatureCollection("projects/ee-ross-superior/assets/train-test/validation_ls7_v2024")
```

## Train the GTB model

```{python}
ls_input_feat = ["SR_B1", "SR_B2", "SR_B3", "SR_B4", "SR_B5", "SR_B7"]
output_label = "class"
class_values = (['cloud',
  'openWater',
  'lightNearShoreSediment',
  'offShoreSediment',
  'darkNearShoreSediment'])
```

### Landsat 7

```{python}
trainedGTB_ls7 = (ee.Classifier.smileGradientTreeBoost(numberOfTrees = 10, seed = 47).train(
  features = training_ls7,
  classProperty = 'byte_property',
  inputProperties = ls_input_feat
))

print(trainedGTB_ls7.getInfo())
```

Unfortunately, there is no current mechanism to save the GTB object as an asset, 
so we are relying on setting the seed here to take care of reproducibility. Let's
also take a look at the variable importance to make sure that this all makes sense.

```{python}
# Variable Importance - Graph  
GTB_ls7_dict = trainedGTB_ls7.explain()

variable_importance = (ee.Dictionary(GTB_ls7_dict)
  .get('importance')
  .getInfo())

# Sort the dictionary by values in descending order
sorted_importance = dict(sorted(variable_importance.items(), key=lambda item: item[1], reverse=True))

# Extract keys and values
keys = list(sorted_importance.keys())
values = list(sorted_importance.values())

# Plot the bar graph
plt.figure(figsize=(10, 6))
plt.barh(keys, values, color='skyblue')

# Adding titles and labels
plt.xlabel('Feature Importance')
plt.ylabel('Band')
plt.title('Feature importance for 5-class GTB model for Landsat 7')

# Reverse the y-axis to show highest value at the top
plt.gca().invert_yaxis()

# Display the plot
plt.tight_layout()
# Display the plot
plt.show()

df = pd.DataFrame(list(sorted_importance.items()), columns=['Band', 'Feature_Importance'])

# And save the variable importance for later use.
df.to_csv('data/output/GTB_LS7_variable_importance_'+v_date+'.csv', index = False)

```

## Evaluate the models

### Landsat 7

```{python}
trainingMatrixGTB_ls7 = (trainedGTB_ls7
  .confusionMatrix())

#convert to pandas dataframe with class info
training_conf_l7 = (pd.DataFrame(
  trainingMatrixGTB_ls7.getInfo(),
  index=[class_values],
  columns =[class_values]
  ))
print('GTB Training Confusion Matrix for Landsat 7:')
print(training_conf_l7)

#reformat and save
training_conf_l7['mission'] = 'Landsat 7'
training_conf_l7.reset_index(inplace = True)
training_conf_l7 = training_conf_l7.rename(columns = {'level_0': 'class'})  
training_conf_l7.to_csv('data/output/GTB_'+v_date+'_l7_training_confusion.csv', index = False)

confusionMatrixGTB_ls7 = (testing_ls7
  .classify(trainedGTB_ls7)
  .errorMatrix('byte_property', "classification"))

#convert to pandas dataframe with class info
confusion_l7 = (pd.DataFrame(
  confusionMatrixGTB_ls7.getInfo(),
  index=[class_values],
  columns =[class_values]
  ))
print('GTB Confusion Matrix for Landsat 7:')
print(confusion_l7)

#reformat and save
confusion_l7['mission'] = 'Landsat 7'
confusion_l7.reset_index(inplace = True)
confusion_l7 = confusion_l7.rename(columns = {'level_0': 'class'})  
confusion_l7.to_csv('data/output/GTB_'+v_date+'_L7_confusion.csv', index = False)

acc_values_GTB_ls7 = (confusionMatrixGTB_ls7.accuracy().getInfo())
print("GTB Confusion Overall Accuracy for Landsat 7: ", acc_values_GTB_ls7)
k_GTB_ls7 = (confusionMatrixGTB_ls7.kappa().getInfo())
print("GTB kappa for LS7: ", k_GTB_ls7)
fs_GTB_ls7 = (confusionMatrixGTB_ls7.fscore().getInfo())
print('GTB fScore for each class: ', fs_GTB_ls7)
```


### Collate model stats, save to data folder

First, we'll copy over some values and make a big pandas dataframe. Note that
the df.copy() function unlinks the original list from the new one. Silly python.

```{python}
accuracy_heads = class_values.copy()
accuracy_heads.extend(['GTB_accuracy', 'GTB_kappa'])
landsat7_perf = fs_GTB_ls7.copy()
landsat7_perf.extend([acc_values_GTB_ls7, k_GTB_ls7])

performance_collation = pd.DataFrame(
  [landsat7_perf],
  index = [
    'Landsat 7'
    ],
  columns = [accuracy_heads]
  )

# reset the index
performance_collation.reset_index(inplace = True)
performance_collation.rename(columns = {'index':'satellite'}).to_csv('data/output/GTB_LS7_'+v_date+'_performance_stats.csv', index = False)
```

<!-- ## Apply model to image stack for Landsat -->

<!-- ### Load the image collection -->

<!-- ```{python} -->
<!-- # filter stack for desired PRs -->
<!-- ROWS = ee.List([27, 28]) -->

<!-- l7 = (ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') -->
<!--   .filter(ee.Filter.lt('CLOUD_COVER', 80)) -->
<!--   .filter(ee.Filter.eq('WRS_PATH', 26)) -->
<!--   .filter(ee.Filter.inList('WRS_ROW', ROWS)) -->
<!--   .filter(ee.Filter.gte('IMAGE_QUALITY', 7)) -->
<!--   .filter(ee.Filter.calendarRange(4,11,'month')) -->
<!--   # mask high atmospheric opacity (conservative decision) -->
<!--   .map(gf.mask_high_atmos_opac) -->
<!--   # mask pixels with any qa flags -->
<!--   .map(gf.mask_qa_flags) -->
<!--   # mask saturated pixels -->
<!--   .map(gf.apply_radsat_mask) -->
<!--   # apply scaling factors -->
<!--   .map(gf.applyScaleFactors)) -->
<!-- ``` -->

<!-- ### Load modeling AOIs and clip stack -->

<!-- And then clip each image by that aoi -->

<!-- ```{python} -->
<!-- l7_aoi = l7.map(gf.clip) -->
<!-- ``` -->

<!-- #### Helper functions -->

<!-- ```{python} -->
<!-- # get CRS info -->
<!-- img_crs = l7.first().projection() -->
<!-- img_crsTrans = img_crs.getInfo().get('transform') -->
<!-- ``` -->

<!-- ### consolidate stack by image date -->

<!-- ```{python} -->
<!-- l7_aoi = l7_aoi.map(gf.addImageDate) -->

<!-- # summarize by missionDate field -->
<!-- uniqueMissDate_l7 = l7_aoi.aggregate_array('missDate').distinct() -->

<!-- ``` -->

<!-- ### Create mosaics -->

<!-- ```{python} -->
<!-- # need a couple of functions that refer to objects in this script -->
<!-- def applyGTB_ls7(image): -->
<!--   # Select the bands that correspond to the input features of the GTB model -->
<!--   imageFeatures = image.select(ls_input_feat) -->
<!--   missDate = image.get('missDate') -->
<!--   # Classify the image using the trained GTB model -->
<!--   classifiedImage = (imageFeatures -->
<!--     .classify(trainedGTB_ls7) -->
<!--     .set('missDate', missDate)) -->
<!--   return image.addBands(classifiedImage) -->

<!-- def applyPerMissionDate_ls7(missDate): -->
<!--   mission = ee.String(missDate).slice(0,9) -->
<!--   date = ee.String(missDate).slice(10,20) -->
<!--   short_stack = (l7 -->
<!--     .filter(ee.Filter.eq('SPACECRAFT_ID', mission)) -->
<!--     .filter(ee.Filter.eq('DATE_ACQUIRED', date))) -->
<!--   oneMissDate = short_stack.mean() -->
<!--   ls_miss_date_GTB = applyGTB_ls7(oneMissDate) -->
<!--   ls_GTB_class = extract_classes(ls_miss_date_GTB) -->
<!--   return (ls_GTB_class.set('missDate', missDate)) -->

<!-- def mosaicStack_l7(missDate): -->
<!--   md_GTB = gf.applyPerMissionDate_ls7(missDate) -->
<!--   return md_GTB -->

<!-- newStack_list_l7 = uniqueMissDate_l7.map(mosaicStack_l7) -->
<!-- newStack_l7 = ee.ImageCollection(newStack_list_l7) -->

<!-- ``` -->

<!-- ### Lighten up each of the stacks to only the bands we care about -->

<!-- ```{python} -->
<!-- lightStack_l7 = newStack_l7.select([ -->
<!--     'classified', -->
<!--     'cloud', -->
<!--     'openWater', -->
<!--     'lightNSSed', -->
<!--     'OSSed', -->
<!--     'dNSSed' -->
<!--     ]) -->

<!-- ``` -->

<!-- ## Export GeoTiffs to drive -->

<!-- ### GTB images for Landsat 7 -->

<!-- ```{python} -->
<!-- date_length_7 = len(uniqueMissDate_l7.getInfo()) -->

<!-- aoi_ee = ee.FeatureCollection('projects/ee-ross-superior/assets/aoi/Superior_AOI_modeling') -->

<!-- def clip(image): -->
<!--   return image.clip(aoi_ee.geometry()) -->

<!-- # export tif to drive -->
<!-- for d in range(date_length_7): -->
<!--   md = uniqueMissDate_l7.get(d) -->
<!--   print(md.getInfo()) -->
<!--   print(str(d+1) + ' of ' + str(date_length_7)) -->
<!--   image = (newStack_l7 -->
<!--     .filter(ee.Filter.eq('missDate', md)) -->
<!--     .first() -->
<!--     .clip(aoi_ee.geometry())) -->
<!--   image_new_class = (gf.classifications_to_one_band(image) -->
<!--     .select('reclass')) -->
<!--   export_image = ee.batch.Export.image.toDrive( -->
<!--     image = image_new_class, -->
<!--     region = aoi_ee.geometry(), -->
<!--     description = 'GTB_v' + v_date + '_' + str(md.getInfo()), -->
<!--     folder = 'GTB_LS7_v'+ v_date, -->
<!--     scale = 30, -->
<!--     crs = img_crs, -->
<!--     maxPixels = 1e13) -->

<!--   #Check how many existing tasks are running and take a break of 5 mins if it's >10 -->
<!--   gf.maximum_no_of_tasks(10, 5*60) -->
<!--   #Send next task. -->
<!--   export_image.start() -->


<!-- # # export as asset -->
<!-- # for d in range(date_length_7): -->
<!-- #   md = uniqueMissDate_l7.get(d) -->
<!-- #   print(md.getInfo()) -->
<!-- #   print(str(d+1) + ' of ' + str(date_length_7)) -->
<!-- #   image = (newStack_l7 -->
<!-- #     .filter(ee.Filter.eq('missDate', md)) -->
<!-- #     .first() -->
<!-- #     .clip(aoi_ee.geometry())) -->
<!-- #   image_new_class = (gf.classifications_to_one_band(image) -->
<!-- #     .select('reclass')) -->
<!-- #   export_image = ee.batch.Export.image.toAsset( -->
<!-- #     image = image_new_class, -->
<!-- #     region = aoi_ee.geometry(), -->
<!-- #     description = 'GTB_v' + v_date + '_' + str(md.getInfo()), -->
<!-- #     assetId = 'projects/ee-ross-superior/assets/LS7/GTB_LS7_'+str(md.getInfo())+'_v'+v_date, -->
<!-- #     scale = 30, -->
<!-- #     crs = img_crs, -->
<!-- #     maxPixels = 1e13) -->
<!-- #    -->
<!-- #   #Check how many existing tasks are running and take a break of 5 mins if it's >10 -->
<!-- #   gf.maximum_no_of_tasks(10, 5*60) -->
<!-- #   #Send next task. -->
<!-- #   export_image.start() -->

<!-- ``` -->


